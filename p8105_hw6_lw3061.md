Homework 6
================
Lucia Wang (lw3061)

## Problem 1

## Problem 2

First, download data:

``` r
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2022-01-01",
    date_max = "2022-12-31") |>
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) |>
  select(name, id, everything())
```

    ## using cached file: C:\Users\wangl\AppData\Local/R/cache/R/rnoaa/noaa_ghcnd/USW00094728.dly

    ## date created (size, mb): 2023-09-28 10:19:41.358543 (8.541)

    ## file min/max dates: 1869-01-01 / 2023-09-30

The simple linear regression will have `tmax` as the response variable
with `tmin` and `prcp` as predictors. Run 5000 bootstraps and estimate
r-squared and log(beta1 \* beta2), then plot the distributions.

``` r
weather_bstrap = weather_df |>
  bootstrap(n=5000) |>
  mutate(models = map(strap, \(df) lm(tmax ~ tmin + prcp, data=df) ),
         results = map(models, broom::tidy),
         rsq = map(models, broom::glance)
         ) |>
  select(-strap, -models) |>
  unnest(results) |> 
  filter(term %in% c("tmin", "prcp")) |>
  group_by(.id) |> 
  mutate(beta1x2 = prod(estimate)) |>
  select(beta1x2, rsq) |> 
  unnest(rsq) |> 
  janitor::clean_names() |>
  select(id, beta1x2, r_squared) |> unique()
```

    ## Adding missing grouping variables: `.id`

``` r
weather_bstrap |> ggplot(aes(x=beta1x2)) + geom_density()
```

![](p8105_hw6_lw3061_files/figure-gfm/unnamed-chunk-3-1.png)<!-- -->

The distribution of the log(beta1 \* beta2) estimates seems to be
centered around 0 with majority of values between -0.01 and 0.01.

``` r
weather_bstrap |> ggplot(aes(x=r_squared)) + geom_density()
```

![](p8105_hw6_lw3061_files/figure-gfm/unnamed-chunk-4-1.png)<!-- -->

The distribution of the r-squared values is pretty high at around 0.92.
The bulk of the estimates fall approximately from 0.9 to 0.95 but skew
left (more higher values).

Now calculate the confidence intervals for the sampled log(beta1 \*
beta2) and r-squared values…

``` r
sum_weather = weather_bstrap |>
  unique() |> ungroup() |> select(-id) |> summarize(betas_mean = mean(beta1x2),
                                              betas_low = quantile(beta1x2, 0.025),
                                              betas_high = quantile(beta1x2, 0.975),
                                              rsq_mean = mean(r_squared),
                                              rsq_low = quantile(r_squared, 0.025),
                                              rsq_high = quantile(r_squared, 0.975))
 sum_weather |> knitr::kable()
```

| betas_mean |  betas_low | betas_high |  rsq_mean |   rsq_low | rsq_high |
|-----------:|-----------:|-----------:|----------:|----------:|---------:|
| -0.0019378 | -0.0095383 |  0.0080054 | 0.9172075 | 0.8884889 | 0.940626 |

After 5000 bootstraps, the 95% CI for the r-squared values is
(0.8884889, 0.940626) and the CI for the log(beta1 \* beta2) values is
(-0.0095383, 0.0080054).

## Problem 3

Import and tidy birthweight data:

``` r
bw = read_csv("birthweight.csv") |>
  mutate(babysex= as.factor(babysex),
         frace = as.factor(frace),
         malform = as.factor(malform),
         mrace = as.factor(mrace))
```

    ## Rows: 4342 Columns: 20
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (20): babysex, bhead, blength, bwt, delwt, fincome, frace, gaweeks, malf...
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

My proposed regression model for birthweight will use mother’s weight at
delivery `delwt`, mother’s age at delivery `momage`, and mother’s age at
menarche `menarche` as predictors, with no interaction terms. I am
curious about these variables because they are related to reproductive
cycles of the mother so they would likely affect the development of the
fetus and thus the birthweight of the baby.

``` r
fit = lm(bwt ~ delwt + momage + menarche, data=bw)
fit |> broom::tidy() |> select(term, estimate, p.value) |> knitr::kable(digits=3)
```

| term        | estimate | p.value |
|:------------|---------:|--------:|
| (Intercept) | 1958.076 |   0.000 |
| delwt       |    6.393 |   0.000 |
| momage      |   15.722 |   0.000 |
| menarche    |   -7.471 |   0.144 |

At a quick glance the estimates have low p-values except for the
estimate for `menarche`. Now I will add residuals and fitted values…

``` r
bw |>
  modelr::add_residuals(fit) |>
  modelr::add_predictions(fit) |>
  ggplot(aes(x=resid, y=pred)) + geom_point(alpha=0.5, size=0.5)
```

![](p8105_hw6_lw3061_files/figure-gfm/unnamed-chunk-8-1.png)<!-- -->

The plot of the fitted values and residuals is not looking very good;
there are some outliers and some clustering of values, so maybe the
linear model isn’t the best.

Now I’ll compare this to 2 other models using the cross-validation
method:

``` r
cv_df = crossv_mc(bw, 10)

cv_df = cv_df |>
  mutate(train = map(train, as_tibble),
         test = map(test, as_tibble)) 

cv_df = cv_df |>
  mutate(
    my_mod = map(train, \(df) lm(bwt ~ delwt + momage + menarche, data=df)),
    main_mod = map(train, \(df) lm(bwt ~ blength + gaweeks, data=df)),
    interact_mod = map(train, \(df) lm(bwt ~ bhead * blength * babysex, data=df))
    ) |>
  mutate(
    rmse_my = map2_dbl(my_mod, test, \(mod, df) rmse(model = mod, data = df)),
    rmse_main = map2_dbl(main_mod, test, \(mod, df) rmse(model = mod, data = df)),
    rmse_interact = map2_dbl(interact_mod, test, \(mod, df) rmse(model = mod, data = df))
    )

cv_df |> select(starts_with("rmse")) |>
  pivot_longer(
    everything(), names_to="model", values_to="rmse", names_prefix="rmse_"
  ) |>
  ggplot(aes(x=model, y=rmse)) + geom_violin()
```

![](p8105_hw6_lw3061_files/figure-gfm/unnamed-chunk-9-1.png)<!-- -->

Based on looking at the root mean squared error, the model with the
interactions between `bhead`, `blength`, and `babysex` seems to be the
best fit as it has the smallest rmse. In contrast, the rmse for my model
is really much higher than the other two models, so it looks like it’s
not optimal.
